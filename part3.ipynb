{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890930bd-b526-4471-bd5e-553cebbf48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330787e7-598b-4d0c-92be-c81c45fa0929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données historiques...\n",
      "root\n",
      " |-- toot_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- reblogs_count: integer (nullable = true)\n",
      " |-- favourites_count: integer (nullable = true)\n",
      " |-- replies_count: integer (nullable = true)\n",
      "\n",
      "+------------------+-------------------+--------------------+------------------+--------+--------+-------------+----------------+-------------+\n",
      "|           toot_id|          timestamp|                text|           user_id|language|hashtags|reblogs_count|favourites_count|replies_count|\n",
      "+------------------+-------------------+--------------------+------------------+--------+--------+-------------+----------------+-------------+\n",
      "|113282845685250307|2024-10-10 11:17:26|a novel llmbased ...|109730266331128291|      en|        |            0|               0|            0|\n",
      "|113282856345151083|2024-10-10 11:20:08|peoples lives are...|109376943622495671|      en|        |            0|               0|            0|\n",
      "|113282885019129605|2024-10-10 11:27:26|generative model ...|109730266331128291|      en|        |            0|               0|            0|\n",
      "|113282887594586600|2024-10-10 11:23:33|it will be a whil...|113238719068128206|      en|        |            0|               0|            0|\n",
      "|113282927114333422|2024-10-10 11:38:08|was actually gonn...|109362220773484592|      en|        |            0|               0|            0|\n",
      "+------------------+-------------------+--------------------+------------------+--------+--------+-------------+----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Utilisateurs avec plus de 2 toots :\n",
      "+-------+----------+\n",
      "|user_id|toot_count|\n",
      "+-------+----------+\n",
      "+-------+----------+\n",
      "\n",
      "Nombre total de toots par date et hashtag :\n",
      "+----+-------+-----------+\n",
      "|date|hashtag|total_toots|\n",
      "+----+-------+-----------+\n",
      "+----+-------+-----------+\n",
      "\n",
      "Hashtag le plus fréquent :\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "+-------+-------------+\n",
      "\n",
      "Nombre total de toots par jour :\n",
      "+----------+-----------+\n",
      "|      date|total_toots|\n",
      "+----------+-----------+\n",
      "|2024-10-10|          7|\n",
      "+----------+-----------+\n",
      "\n",
      "Longueur moyenne des toots :\n",
      "+-------------------+\n",
      "|average_toot_length|\n",
      "+-------------------+\n",
      "| 500.14285714285717|\n",
      "+-------------------+\n",
      "\n",
      "Nombre total de toots : 7\n",
      "Temps sans optimisation : 0.18770480155944824 secondes\n",
      "Nombre total de toots (après repartition): 7\n",
      "Temps avec repartition : 0.36062169075012207 secondes\n",
      "Nombre total de toots (après cache): 7\n",
      "Temps avec cache : 0.44656848907470703 secondes\n",
      "Analyse et optimisation terminées.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, avg, desc, col, explode, to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import split, explode, to_date\n",
    "from pyspark.sql.functions import length\n",
    "import time\n",
    "\n",
    "\n",
    "# Créer une SparkSession pour le traitement par lots des données historiques\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BatchProcessingMastodon\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.25\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Paramètres de connexion à PostgreSQL\n",
    "db_host = \"some-postgres\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"mastodon_data\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"mysecretpassword\"\n",
    "db_url = f\"jdbc:postgresql://{db_host}:{db_port}/{db_name}\"\n",
    "db_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Charge les données historiques depuis PostgreSQL\n",
    "print(\"Chargement des données historiques...\")\n",
    "filtered_toots_df = spark.read.jdbc(url=db_url, table=\"filtered_toots\", properties=db_properties)\n",
    "\n",
    "# Vérifie le schéma et afficher quelques lignes\n",
    "filtered_toots_df.printSchema()\n",
    "filtered_toots_df.show(5)\n",
    "\n",
    "# Filtre les toots basés sur l'activité des utilisateurs \n",
    "X = 2  \n",
    "\n",
    "# Calcule le nombre de toots par utilisateur\n",
    "user_toot_counts = filtered_toots_df.groupBy(\"user_id\").agg(count(\"*\").alias(\"toot_count\"))\n",
    "\n",
    "# Filtre les utilisateurs avec plus de X toots\n",
    "active_users = user_toot_counts.filter(col(\"toot_count\") > X)\n",
    "\n",
    "print(f\"Utilisateurs avec plus de {X} toots :\")\n",
    "active_users.show()\n",
    "\n",
    "# Join avec les toots originaux pour obtenir les toots de ces utilisateurs\n",
    "active_users_toots = filtered_toots_df.join(active_users, on=\"user_id\", how=\"inner\")\n",
    "\n",
    "\n",
    "# Extrai la date à partir du timestamp\n",
    "toots_with_date = active_users_toots.withColumn(\"date\", to_date(col(\"timestamp\")))\n",
    "\n",
    "toots_with_hashtags = toots_with_date.withColumn(\"hashtag\", explode(split(col(\"hashtags\"), \",\")))\n",
    "\n",
    "# Calcule le nombre total de toots par date et hashtag\n",
    "toots_by_date_hashtag = toots_with_hashtags.groupBy(\"date\", \"hashtag\").agg(count(\"*\").alias(\"total_toots\"))\n",
    "\n",
    "print(\"Nombre total de toots par date et hashtag :\")\n",
    "toots_by_date_hashtag.orderBy(desc(\"total_toots\")).show()\n",
    "\n",
    "# Identifie le hashtag le plus fréquent\n",
    "most_frequent_hashtag = toots_with_hashtags.groupBy(\"hashtag\").agg(count(\"*\").alias(\"hashtag_count\")) \\\n",
    "    .orderBy(desc(\"hashtag_count\")).limit(1)\n",
    "\n",
    "print(\"Hashtag le plus fréquent :\")\n",
    "most_frequent_hashtag.show()\n",
    "\n",
    "\n",
    "# Compte le nombre total de toots par jour\n",
    "total_toots_per_day = filtered_toots_df.withColumn(\"date\", to_date(col(\"timestamp\"))) \\\n",
    "    .groupBy(\"date\").agg(count(\"*\").alias(\"total_toots\")) \\\n",
    "    .orderBy(\"date\")\n",
    "\n",
    "print(\"Nombre total de toots par jour :\")\n",
    "total_toots_per_day.show()\n",
    "\n",
    "filtered_toots_df = filtered_toots_df.withColumn(\"text_length\", length(col(\"text\")))\n",
    "\n",
    "average_toot_length = filtered_toots_df.agg(avg(\"text_length\").alias(\"average_toot_length\"))\n",
    "\n",
    "print(\"Longueur moyenne des toots :\")\n",
    "average_toot_length.show()\n",
    "\n",
    "\n",
    "\n",
    "# Mesure les performances avant optimisation\n",
    "\n",
    "start_time = time.time()\n",
    "total_toots = filtered_toots_df.count()\n",
    "end_time = time.time()\n",
    "print(f\"Nombre total de toots : {total_toots}\")\n",
    "print(f\"Temps sans optimisation : {end_time - start_time} secondes\")\n",
    "\n",
    "\n",
    "repartitioned_df = filtered_toots_df.repartition(8)  \n",
    "\n",
    "start_time = time.time()\n",
    "total_toots = repartitioned_df.count()\n",
    "end_time = time.time()\n",
    "print(f\"Nombre total de toots (après repartition): {total_toots}\")\n",
    "print(f\"Temps avec repartition : {end_time - start_time} secondes\")\n",
    "\n",
    "\n",
    "filtered_toots_df.cache()\n",
    "\n",
    "start_time = time.time()\n",
    "total_toots = filtered_toots_df.count()\n",
    "end_time = time.time()\n",
    "print(f\"Nombre total de toots (après cache): {total_toots}\")\n",
    "print(f\"Temps avec cache : {end_time - start_time} secondes\")\n",
    "\n",
    "\n",
    "print(\"Analyse et optimisation terminées.\")\n",
    "\n",
    "# Arrête la SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b192111-8af3-4ffc-8618-d9ffc1693313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
